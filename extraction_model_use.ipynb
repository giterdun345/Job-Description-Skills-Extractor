{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read me text for requirements\n",
    "<ul>\n",
    "    <li> pandas== 1.0.5\n",
    "    <li> numpy== 1.18.5\n",
    "    <li> nltk== 3.2.5\n",
    "    <li> gast== 0.2.2\n",
    "    <li> tensorflow== 1.15.2\n",
    "    <li> bert-tensorflow == 1.0.1\n",
    "    <li> tensorflow-hub == \n",
    "    <li> tqdm==\n",
    "    <li> ipywidgets==\n",
    "        \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm_notebook \n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tensorflow.keras import backend as K\n",
    "sess = tf.Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input job description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste job description hereC3.ai is a leading enterprise AI software provider for accelerating digital transformation. The comprehensive and proven C3 AI Suite uses a model-driven abstraction layer to enable organizations to develop, deploy, and operate enterprise scale AI applications 40x to 100x faster than alternative approaches. www.c3.ai  As a Data Scientist, you will participate in the definition of new analytics capabilities able to provide our customers with the information they need to make proper decisions to support our customers in operating the internet of things (IoT). In addition, you will help find the appropriate machine learning / data mining algorithms to answer these questions. Finally, you will be responsible for implementing this into the product and making it available to our customers.  Qualified candidates will have an in-depth knowledge of most common machine learning techniques and their application. You will also understand the limitations of these algorithms and how to tweak them or derive from them to achieve similar results at large-scale.  Your Responsibilities Driving adoption of Deep Learning systems into next-generation of C3.ai products. Designing and deploying Machine Learning algorithms for industrial applications such as fraud detection and predictive maintenance. Collaborating with data and subject matter experts from C3.ai and its customer teams to seek, understand, validate, interpret, and correctly use new data elements.   Requirements MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields. Applied Machine Learning experience (regression and classification, supervised, and unsupervised learning). Strong mathematical background (linear algebra, calculus, probability and statistics). Experience with scalable ML (MapReduce, streaming). Ability to drive a project and work both independently and in a team. Smart, motivated, can do attitude, and seeks to make a difference. Excellent verbal and written communication.   Preferred Experience with JavaScript and prototyping languages such as Python and R. Experience with Java and Scala is a plus. Knowledge in electrical engineering and cyber-physical systems is a plus. A portfolio of projects (GitHub, papers, etc.) is a plus.  C3.ai provides a competitive compensation package and excellent benefits including: Competitive salary, generous stock options, 401K, medical, dental, and vision benefits. At the office, we offer a fully stocked kitchen with catered breakfast and lunch, table tennis and pool table, free membership at our on-site gym, Friday evening social hours with food, drink and music and a fun team of great people.  C3.ai is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status.\n"
     ]
    }
   ],
   "source": [
    "# as if input was given on website \n",
    "jd = input('Paste job description here');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize an Tag POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c3.ai', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('leading', 'VBG'),\n",
       " ('enterprise', 'NN'),\n",
       " ('ai', 'NN'),\n",
       " ('software', 'NN'),\n",
       " ('provider', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('accelerating', 'VBG'),\n",
       " ('digital', 'JJ'),\n",
       " ('transformation', 'NN'),\n",
       " ('.', '.'),\n",
       " ('the', 'DT'),\n",
       " ('comprehensive', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('proven', 'JJ'),\n",
       " ('c3', 'NN'),\n",
       " ('ai', 'VBP'),\n",
       " ('suite', 'JJ'),\n",
       " ('uses', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('model-driven', 'JJ'),\n",
       " ('abstraction', 'NN'),\n",
       " ('layer', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('enable', 'VB'),\n",
       " ('organizations', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('develop', 'VB'),\n",
       " (',', ','),\n",
       " ('deploy', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('operate', 'VBP'),\n",
       " ('enterprise', 'NN'),\n",
       " ('scale', 'NN'),\n",
       " ('ai', 'VBP'),\n",
       " ('applications', 'NNS'),\n",
       " ('40x', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('100x', 'CD'),\n",
       " ('faster', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('alternative', 'JJ'),\n",
       " ('approaches', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('www.c3.ai', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('data', 'NN'),\n",
       " ('scientist', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('participate', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('definition', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('new', 'JJ'),\n",
       " ('analytics', 'NNS'),\n",
       " ('capabilities', 'NNS'),\n",
       " ('able', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('provide', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('customers', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('information', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('proper', 'JJ'),\n",
       " ('decisions', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('support', 'VB'),\n",
       " ('our', 'PRP$'),\n",
       " ('customers', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('operating', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('internet', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('things', 'NNS'),\n",
       " ('(', '('),\n",
       " ('iot', 'NN'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('in', 'IN'),\n",
       " ('addition', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('help', 'VB'),\n",
       " ('find', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('appropriate', 'JJ'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('/', 'NNP'),\n",
       " ('data', 'NNS'),\n",
       " ('mining', 'NN'),\n",
       " ('algorithms', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('answer', 'VB'),\n",
       " ('these', 'DT'),\n",
       " ('questions', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('finally', 'RB'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('responsible', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('implementing', 'VBG'),\n",
       " ('this', 'DT'),\n",
       " ('into', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('product', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('making', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('available', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('customers', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('qualified', 'VBN'),\n",
       " ('candidates', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('in-depth', 'JJ'),\n",
       " ('knowledge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('common', 'JJ'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('techniques', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('application', 'NN'),\n",
       " ('.', '.'),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('understand', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('limitations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('algorithms', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('how', 'WRB'),\n",
       " ('to', 'TO'),\n",
       " ('tweak', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('or', 'CC'),\n",
       " ('derive', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('achieve', 'VB'),\n",
       " ('similar', 'JJ'),\n",
       " ('results', 'NNS'),\n",
       " ('at', 'IN'),\n",
       " ('large-scale', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('your', 'PRP$'),\n",
       " ('responsibilities', 'NNS'),\n",
       " ('driving', 'VBG'),\n",
       " ('adoption', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('deep', 'JJ'),\n",
       " ('learning', 'VBG'),\n",
       " ('systems', 'NNS'),\n",
       " ('into', 'IN'),\n",
       " ('next-generation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('c3.ai', 'NN'),\n",
       " ('products', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('designing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('deploying', 'VBG'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('algorithms', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('industrial', 'JJ'),\n",
       " ('applications', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('fraud', 'NN'),\n",
       " ('detection', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('predictive', 'JJ'),\n",
       " ('maintenance', 'NN'),\n",
       " ('.', '.'),\n",
       " ('collaborating', 'VBG'),\n",
       " ('with', 'IN'),\n",
       " ('data', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('subject', 'JJ'),\n",
       " ('matter', 'NN'),\n",
       " ('experts', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('c3.ai', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('its', 'PRP$'),\n",
       " ('customer', 'NN'),\n",
       " ('teams', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('seek', 'VB'),\n",
       " (',', ','),\n",
       " ('understand', 'VB'),\n",
       " (',', ','),\n",
       " ('validate', 'NN'),\n",
       " (',', ','),\n",
       " ('interpret', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('correctly', 'RB'),\n",
       " ('use', 'VBP'),\n",
       " ('new', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('elements', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('requirements', 'NNS'),\n",
       " ('ms', 'VBD'),\n",
       " ('or', 'CC'),\n",
       " ('phd', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('computer', 'NN'),\n",
       " ('science', 'NN'),\n",
       " (',', ','),\n",
       " ('electrical', 'JJ'),\n",
       " ('engineering', 'NN'),\n",
       " (',', ','),\n",
       " ('statistics', 'NNS'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('equivalent', 'JJ'),\n",
       " ('fields', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('applied', 'VBN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('experience', 'NN'),\n",
       " ('(', '('),\n",
       " ('regression', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('classification', 'NN'),\n",
       " (',', ','),\n",
       " ('supervised', 'VBN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('unsupervised', 'JJ'),\n",
       " ('learning', 'NN'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('strong', 'JJ'),\n",
       " ('mathematical', 'JJ'),\n",
       " ('background', 'NN'),\n",
       " ('(', '('),\n",
       " ('linear', 'JJ'),\n",
       " ('algebra', 'NN'),\n",
       " (',', ','),\n",
       " ('calculus', 'NN'),\n",
       " (',', ','),\n",
       " ('probability', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('statistics', 'NNS'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('experience', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('scalable', 'JJ'),\n",
       " ('ml', 'NN'),\n",
       " ('(', '('),\n",
       " ('mapreduce', 'NN'),\n",
       " (',', ','),\n",
       " ('streaming', 'VBG'),\n",
       " (')', ')'),\n",
       " ('.', '.'),\n",
       " ('ability', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('drive', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('work', 'VB'),\n",
       " ('both', 'DT'),\n",
       " ('independently', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('team', 'NN'),\n",
       " ('.', '.'),\n",
       " ('smart', 'NN'),\n",
       " (',', ','),\n",
       " ('motivated', 'VBN'),\n",
       " (',', ','),\n",
       " ('can', 'MD'),\n",
       " ('do', 'VB'),\n",
       " ('attitude', 'VB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('seeks', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('difference', 'NN'),\n",
       " ('.', '.'),\n",
       " ('excellent', 'JJ'),\n",
       " ('verbal', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('written', 'VBN'),\n",
       " ('communication', 'NN'),\n",
       " ('.', '.'),\n",
       " ('preferred', 'JJ'),\n",
       " ('experience', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('javascript', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('prototyping', 'VBG'),\n",
       " ('languages', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('python', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('r.', 'VB'),\n",
       " ('experience', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('java', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('scala', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('plus', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('knowledge', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('electrical', 'JJ'),\n",
       " ('engineering', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('cyber-physical', 'JJ'),\n",
       " ('systems', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('plus', 'NN'),\n",
       " ('.', '.'),\n",
       " ('a', 'DT'),\n",
       " ('portfolio', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('projects', 'NNS'),\n",
       " ('(', '('),\n",
       " ('github', 'NN'),\n",
       " (',', ','),\n",
       " ('papers', 'NNS'),\n",
       " (',', ','),\n",
       " ('etc', 'FW'),\n",
       " ('.', '.'),\n",
       " (')', ')'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('plus', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('c3.ai', 'NN'),\n",
       " ('provides', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('competitive', 'JJ'),\n",
       " ('compensation', 'NN'),\n",
       " ('package', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('excellent', 'JJ'),\n",
       " ('benefits', 'NNS'),\n",
       " ('including', 'VBG'),\n",
       " (':', ':'),\n",
       " ('competitive', 'JJ'),\n",
       " ('salary', 'NN'),\n",
       " (',', ','),\n",
       " ('generous', 'JJ'),\n",
       " ('stock', 'NN'),\n",
       " ('options', 'NNS'),\n",
       " (',', ','),\n",
       " ('401k', 'CD'),\n",
       " (',', ','),\n",
       " ('medical', 'JJ'),\n",
       " (',', ','),\n",
       " ('dental', 'JJ'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('vision', 'NN'),\n",
       " ('benefits', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('office', 'NN'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('offer', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('fully', 'RB'),\n",
       " ('stocked', 'VBN'),\n",
       " ('kitchen', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('catered', 'VBN'),\n",
       " ('breakfast', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('lunch', 'NN'),\n",
       " (',', ','),\n",
       " ('table', 'JJ'),\n",
       " ('tennis', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('pool', 'NN'),\n",
       " ('table', 'NN'),\n",
       " (',', ','),\n",
       " ('free', 'JJ'),\n",
       " ('membership', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('on-site', 'JJ'),\n",
       " ('gym', 'NN'),\n",
       " (',', ','),\n",
       " ('friday', 'JJ'),\n",
       " ('evening', 'VBG'),\n",
       " ('social', 'JJ'),\n",
       " ('hours', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('food', 'NN'),\n",
       " (',', ','),\n",
       " ('drink', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('music', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('fun', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('great', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('c3.ai', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('proud', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('equal', 'JJ'),\n",
       " ('opportunity', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('affirmative', 'JJ'),\n",
       " ('action', 'NN'),\n",
       " ('employer', 'NN'),\n",
       " ('.', '.'),\n",
       " ('we', 'PRP'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('discriminate', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('basis', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('legally', 'RB'),\n",
       " ('protected', 'VBN'),\n",
       " ('characteristics', 'NNS'),\n",
       " (',', ','),\n",
       " ('including', 'VBG'),\n",
       " ('disabled', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('veteran', 'JJ'),\n",
       " ('status', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input must be tokenized and pos tagging is done with vamnilla nltk pos tag\n",
    "tokens = nltk.word_tokenize(jd.lower())\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of identified POS patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noun phrase\n",
    "# first pattern for extraction\n",
    "# an optional determinate followed by any number of adjectives and a noun, plural noun or proper noun\n",
    "grammar1 = ('''Noun Phrases: {<DT>?<JJ>*<NN|NNS|NNP>+}''')\n",
    "chunkParser = nltk.RegexpParser(grammar1)\n",
    "tree1 = chunkParser.parse(tagged)\n",
    "\n",
    "# typical noun phrase pattern appending to be concatted later\n",
    "g1_chunks = []\n",
    "for subtree in tree1.subtrees(filter=lambda t: t.label() == 'Noun Phrases'):\n",
    "    # print(subtree)\n",
    "    g1_chunks.append(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun phrase variation; \n",
    "# second pattern for extraction\n",
    "# preposition maybe, any number of adjective or nouns, any plural nouns or singular nouns\n",
    "grammar2 = ('''NP2: {<IN>?<JJ|NN>*<NNS|NN>} ''')\n",
    "chunkParser = nltk.RegexpParser(grammar2)\n",
    "tree2 = chunkParser.parse(tagged)\n",
    "\n",
    "# variation of a noun phrase pattern to be pickled for later analyses\n",
    "g2_chunks = []\n",
    "for subtree in tree2.subtrees(filter=lambda t: t.label() == 'NP2'):\n",
    "    # print(subtree)\n",
    "    g2_chunks.append(subtree)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third pattern for extraction\n",
    "# any sort of verb followed by any number of nouns\n",
    "grammar3 = ('''\n",
    "    VS: {<VBG|VBZ|VBP|VBD|VB|VBN><NNS|NN>*}\n",
    "    ''')\n",
    "chunkParser = nltk.RegexpParser(grammar3)\n",
    "tree3 = chunkParser.parse(tagged)\n",
    "\n",
    "# verb-noun pattern appending to be concatted later\n",
    "g3_chunks = []\n",
    "for subtree in tree3.subtrees(filter=lambda t: t.label() == 'VS'):\n",
    "    # print(subtree)\n",
    "    g3_chunks.append(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth pattern for extraction\n",
    "# any number of a singular or plural noun followed by a comma followed by the same noun, noun, noun pattern\n",
    "grammar4 = ('''\n",
    "    Commas: {<NN|NNS>*<,><NN|NNS>*<,><NN|NNS>*} \n",
    "    ''')\n",
    "chunkParser = nltk.RegexpParser(grammar4)\n",
    "tree4 = chunkParser.parse(tagged)\n",
    "\n",
    "# common pattern of listing skills appending to be concatted later\n",
    "g4_chunks = []\n",
    "for subtree in tree4.subtrees(filter=lambda t: t.label() == 'Commas'):\n",
    "    # print(subtree)\n",
    "    g4_chunks.append(subtree)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 119 Sample Size: 11.9\n",
      "Length: 122 Sample Size: 12.200000000000001\n",
      "Length: 67 Sample Size: 6.7\n",
      "Length: 5 Sample Size: 0.5\n"
     ]
    }
   ],
   "source": [
    "# sample size reused from prior cell use just in case a sample would be \n",
    "# used to reduce the amount of extractions to go through\n",
    "print('Length:', len(g1_chunks), 'Sample Size:', len(g1_chunks) * .10)\n",
    "print('Length:', len(g2_chunks), 'Sample Size:', len(g2_chunks) * .10) \n",
    "print('Length:', len(g3_chunks), 'Sample Size:', len(g3_chunks) * .10)\n",
    "print('Length:', len(g4_chunks), 'Sample Size:', len(g4_chunks) * .10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(chunks):\n",
    "    '''creates a dataframe that easily parses the chunks data \n",
    "    '''\n",
    "    df = pd.DataFrame(chunks)    \n",
    "    df.fillna('X', inplace = True)\n",
    "    \n",
    "    pattern = []\n",
    "    for row in df.values:\n",
    "        phrase = ''\n",
    "        for tup in row:\n",
    "            # needs a space at the end for seperation\n",
    "            phrase += tup[0] + ' '\n",
    "        phrase = ''.join(phrase)\n",
    "        # could use padding tages but encoder method will provide during \n",
    "        # tokenizing/embeddings; X can replace paddding for now\n",
    "        pattern.append( phrase.replace('X', '').strip())\n",
    "    df['phrase'] = pattern\n",
    "    # only returns 10% of each dataframe to be used \n",
    "    return df.phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one training corpus with 10% of each POS regex identification\n",
    "chunked = pd.concat([data_process(g1_chunks),\n",
    "                      data_process(g2_chunks), \n",
    "                      data_process(g3_chunks),\n",
    "                      data_process(g4_chunks)], \n",
    "                        ignore_index = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "        \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "      When running eval/predict on the TPU, we need to pad the number of examples\n",
    "      to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "      size. The alternative is to drop the last batch, which is bad because it means\n",
    "      the entire output data won't be generated.\n",
    "      We use this class instead of `None` because treating `None` as padding\n",
    "      battches could cause silent errors.\n",
    "      \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# function for intializing the variables which should not be forgotten!!!!!!!\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marti\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\marti\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\bert\\tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\nlp_env\\lib\\site-packages\\ipykernel_launcher.py:89: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21d938e7c384c298d42f3aa5b0211b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Converting examples to features', max=313.0, style=Progreâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unseen = np.array(chunked)\n",
    "unseen_text = unseen[:, np.newaxis]\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "# Convert data to InputExample format\n",
    "unseen_examples = convert_text_to_examples(unseen_text, np.zeros((len(unseen_text),1)))\n",
    "\n",
    "# Convert to features\n",
    "(unseen_input_ids, unseen_input_masks, unseen_segment_ids, unseen_labels \n",
    ") = convert_examples_to_features(tokenizer,\n",
    "                                 unseen_examples,\n",
    "                                 max_seq_length = 18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  1039,  2509, ...,     0,     0,     0],\n",
       "       [  101,  6960,  9932, ...,     0,     0,     0],\n",
       "       [  101,  3617,  8651, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  3330,  1010, ...,     0,     0,     0],\n",
       "       [  101, 11208,  1010, ...,     0,     0,     0],\n",
       "       [  101, 21025,  2705, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    ''' a function had to be added at the end in order to save the model due to \n",
    "    not identifying the shape early in the model build; as a result a function \n",
    "    that overrides original configuration file was made from issues section on guthub'''\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(BertLayer, self).get_config().copy()\n",
    "        config.update({\n",
    "            'n_fine_tune_layers': self.n_fine_tune_layers,\n",
    "            # 'trainable': self.trainable,\n",
    "            # 'output_size': self.output_size,\n",
    "            'pooling': self.pooling,\n",
    "            'bert_path': self.bert_path,\n",
    "        })\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Archetecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model lines indicated where to change the model when tweaking\n",
    "def build_model(max_seq_length = 18): \n",
    "    # three inputs for id, mask and segments of each phrase\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    # first layer where bert embeddings are given to the \"bert-accepted\"tokenized inputs\n",
    "    bert_output = BertLayer(n_fine_tune_layers=10)(bert_inputs)\n",
    "    # five dense layers, decreasing width with each layer\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(bert_output)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(24, activation='tanh')(x)\n",
    "    x = tf.keras.layers.Dense(12, activation='relu')(x)\n",
    "    # softmax activation on final layer to deliver probability values of predictions\n",
    "    pred = tf.keras.layers.Dense(1, activation='softmax')(x)\n",
    "    # optimizer remained throughout iterations\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.00001)\n",
    "    # load em up\n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    # compied and ready to run; metrics stayed the same accuracy added for real time analysis of training\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          98432       bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           2080        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 24)           792         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 12)           300         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            13          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 110,214,763\n",
      "Trainable params: 71,579,185\n",
      "Non-trainable params: 38,635,578\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # # Clear and load model existing from prior use of cell in colab notebook\n",
    "model = None\n",
    "model = build_model(18)\n",
    "#initializing the variables which can often be forgotten\n",
    "initialize_vars(sess)\n",
    "# C:\\Users\\marti\\Job Description Analysis\\POS Tagging & Classification Model\n",
    "model.load_weights(r'C:\\Users\\marti\\Job Description Analysis\\POS Tagging & Classification Model\\extraction_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predictions after we clear and reload model\n",
    "save_preds = model.predict([unseen_input_ids, \n",
    "                            unseen_input_masks, \n",
    "                            unseen_segment_ids]\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(dict(list(zip(unseen, save_preds))))\n",
    "predictions = predictions.T\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# predictions.to_csv('predictions2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c3.ai</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise ai software provider</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital transformation</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proven c3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a model-driven abstraction layer</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organizations</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise scale</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applications</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternative approaches</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.c3.ai</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a data scientist</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the definition</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new analytics capabilities</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customers</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the information</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper decisions</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the internet</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>things</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iot</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the appropriate machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/ data mining algorithms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these questions</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the product</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidates</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an in-depth knowledge</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techniques</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the limitations</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these algorithms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar results</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>responsibilities</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adoption</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systems</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next-generation</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3.ai products</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designing</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industrial applications</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud detection</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictive maintenance</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject matter experts</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer teams</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validate</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interpret</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new data elements</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>requirements</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phd</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer science</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electrical engineering</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equivalent fields</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unsupervised learning</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong mathematical background</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear algebra</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculus</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probability</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scalable ml</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mapreduce</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a project</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a team</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smart</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a difference</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preferred experience</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javascript</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>languages</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scala</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyber-physical systems</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a plus</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a portfolio</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>projects</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>papers</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a competitive compensation package</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent benefits</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competitive salary</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generous stock options</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision benefits</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the office</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchen</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table tennis</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pool table</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free membership</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on-site gym</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social hours</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drink</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a fun team</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great people</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an equal opportunity</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affirmative action employer</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the basis</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characteristics</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veteran status</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-driven abstraction layer</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than alternative approaches</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definition</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of new analytics</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capabilities</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of things</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in addition</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appropriate machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mining algorithms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>questions</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in-depth knowledge</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>limitations</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into next-generation</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of c3.ai products</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for industrial applications</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as fraud detection</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from c3.ai</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new data</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elements</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in computer science</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with scalable ml</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>project</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difference</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with javascript</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as python</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with java</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in electrical engineering</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plus</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portfolio</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of projects</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competitive compensation package</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with food</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun team</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of great people</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal opportunity</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basis</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leading enterprise ai software provider</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accelerating</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uses</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enable organizations</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>develop</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operate enterprise scale</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai applications</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participate</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provide</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operating</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implementing</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>making</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualified candidates</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning techniques</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweak</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derive</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achieve</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driving adoption</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning systems</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploying machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning algorithms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collaborating</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seek</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ms</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applied machine</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning experience</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supervised</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>streaming</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motivated</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attitude</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seeks</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written communication</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prototyping languages</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r. experience</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provides</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>including</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stocked kitchen</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catered breakfast</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evening</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discriminate</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protected characteristics</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, deploy ,</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>, validate , interpret</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering , statistics ,</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algebra , calculus , probability</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>github , papers ,</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "c3.ai                                    1.0\n",
       "enterprise ai software provider          1.0\n",
       "digital transformation                   1.0\n",
       "proven c3                                1.0\n",
       "a model-driven abstraction layer         1.0\n",
       "organizations                            1.0\n",
       "deploy                                   1.0\n",
       "enterprise scale                         1.0\n",
       "applications                             1.0\n",
       "alternative approaches                   1.0\n",
       "www.c3.ai                                1.0\n",
       "a data scientist                         1.0\n",
       "the definition                           1.0\n",
       "new analytics capabilities               1.0\n",
       "customers                                1.0\n",
       "the information                          1.0\n",
       "proper decisions                         1.0\n",
       "the internet                             1.0\n",
       "things                                   1.0\n",
       "iot                                      1.0\n",
       "addition                                 1.0\n",
       "the appropriate machine                  1.0\n",
       "/ data mining algorithms                 1.0\n",
       "these questions                          1.0\n",
       "the product                              1.0\n",
       "candidates                               1.0\n",
       "an in-depth knowledge                    1.0\n",
       "common machine                           1.0\n",
       "techniques                               1.0\n",
       "application                              1.0\n",
       "the limitations                          1.0\n",
       "these algorithms                         1.0\n",
       "similar results                          1.0\n",
       "responsibilities                         1.0\n",
       "adoption                                 1.0\n",
       "systems                                  1.0\n",
       "next-generation                          1.0\n",
       "c3.ai products                           1.0\n",
       "designing                                1.0\n",
       "machine                                  1.0\n",
       "algorithms                               1.0\n",
       "industrial applications                  1.0\n",
       "fraud detection                          1.0\n",
       "predictive maintenance                   1.0\n",
       "data                                     1.0\n",
       "subject matter experts                   1.0\n",
       "customer teams                           1.0\n",
       "validate                                 1.0\n",
       "interpret                                1.0\n",
       "new data elements                        1.0\n",
       "requirements                             1.0\n",
       "phd                                      1.0\n",
       "computer science                         1.0\n",
       "electrical engineering                   1.0\n",
       "statistics                               1.0\n",
       "equivalent fields                        1.0\n",
       "experience                               1.0\n",
       "regression                               1.0\n",
       "classification                           1.0\n",
       "unsupervised learning                    1.0\n",
       "strong mathematical background           1.0\n",
       "linear algebra                           1.0\n",
       "calculus                                 1.0\n",
       "probability                              1.0\n",
       "scalable ml                              1.0\n",
       "mapreduce                                1.0\n",
       "ability                                  1.0\n",
       "a project                                1.0\n",
       "a team                                   1.0\n",
       "smart                                    1.0\n",
       "a difference                             1.0\n",
       "communication                            1.0\n",
       "preferred experience                     1.0\n",
       "javascript                               1.0\n",
       "languages                                1.0\n",
       "python                                   1.0\n",
       "java                                     1.0\n",
       "scala                                    1.0\n",
       "knowledge                                1.0\n",
       "cyber-physical systems                   1.0\n",
       "a plus                                   1.0\n",
       "a portfolio                              1.0\n",
       "projects                                 1.0\n",
       "github                                   1.0\n",
       "papers                                   1.0\n",
       "a competitive compensation package       1.0\n",
       "excellent benefits                       1.0\n",
       "competitive salary                       1.0\n",
       "generous stock options                   1.0\n",
       "vision benefits                          1.0\n",
       "the office                               1.0\n",
       "kitchen                                  1.0\n",
       "breakfast                                1.0\n",
       "lunch                                    1.0\n",
       "table tennis                             1.0\n",
       "pool table                               1.0\n",
       "free membership                          1.0\n",
       "on-site gym                              1.0\n",
       "social hours                             1.0\n",
       "food                                     1.0\n",
       "drink                                    1.0\n",
       "music                                    1.0\n",
       "a fun team                               1.0\n",
       "great people                             1.0\n",
       "an equal opportunity                     1.0\n",
       "affirmative action employer              1.0\n",
       "the basis                                1.0\n",
       "characteristics                          1.0\n",
       "veteran status                           1.0\n",
       "model-driven abstraction layer           1.0\n",
       "than alternative approaches              1.0\n",
       "data scientist                           1.0\n",
       "definition                               1.0\n",
       "of new analytics                         1.0\n",
       "capabilities                             1.0\n",
       "information                              1.0\n",
       "internet                                 1.0\n",
       "of things                                1.0\n",
       "in addition                              1.0\n",
       "appropriate machine                      1.0\n",
       "mining algorithms                        1.0\n",
       "questions                                1.0\n",
       "product                                  1.0\n",
       "in-depth knowledge                       1.0\n",
       "limitations                              1.0\n",
       "into next-generation                     1.0\n",
       "of c3.ai products                        1.0\n",
       "for industrial applications              1.0\n",
       "as fraud detection                       1.0\n",
       "with data                                1.0\n",
       "from c3.ai                               1.0\n",
       "new data                                 1.0\n",
       "elements                                 1.0\n",
       "in computer science                      1.0\n",
       "with scalable ml                         1.0\n",
       "project                                  1.0\n",
       "team                                     1.0\n",
       "difference                               1.0\n",
       "with javascript                          1.0\n",
       "as python                                1.0\n",
       "with java                                1.0\n",
       "in electrical engineering                1.0\n",
       "plus                                     1.0\n",
       "portfolio                                1.0\n",
       "of projects                              1.0\n",
       "competitive compensation package         1.0\n",
       "office                                   1.0\n",
       "with food                                1.0\n",
       "fun team                                 1.0\n",
       "of great people                          1.0\n",
       "equal opportunity                        1.0\n",
       "basis                                    1.0\n",
       "is                                       1.0\n",
       "leading enterprise ai software provider  1.0\n",
       "accelerating                             1.0\n",
       "ai                                       1.0\n",
       "uses                                     1.0\n",
       "enable organizations                     1.0\n",
       "develop                                  1.0\n",
       "operate enterprise scale                 1.0\n",
       "ai applications                          1.0\n",
       "participate                              1.0\n",
       "provide                                  1.0\n",
       "need                                     1.0\n",
       "make                                     1.0\n",
       "support                                  1.0\n",
       "operating                                1.0\n",
       "help                                     1.0\n",
       "find                                     1.0\n",
       "learning                                 1.0\n",
       "answer                                   1.0\n",
       "be                                       1.0\n",
       "implementing                             1.0\n",
       "making                                   1.0\n",
       "qualified candidates                     1.0\n",
       "have                                     1.0\n",
       "learning techniques                      1.0\n",
       "understand                               1.0\n",
       "tweak                                    1.0\n",
       "derive                                   1.0\n",
       "achieve                                  1.0\n",
       "driving adoption                         1.0\n",
       "learning systems                         1.0\n",
       "deploying machine                        1.0\n",
       "learning algorithms                      1.0\n",
       "collaborating                            1.0\n",
       "seek                                     1.0\n",
       "use                                      1.0\n",
       "ms                                       1.0\n",
       "applied machine                          1.0\n",
       "learning experience                      1.0\n",
       "supervised                               1.0\n",
       "streaming                                1.0\n",
       "drive                                    1.0\n",
       "work                                     1.0\n",
       "motivated                                1.0\n",
       "do                                       1.0\n",
       "attitude                                 1.0\n",
       "seeks                                    1.0\n",
       "written communication                    1.0\n",
       "prototyping languages                    1.0\n",
       "r. experience                            1.0\n",
       "provides                                 1.0\n",
       "including                                1.0\n",
       "offer                                    1.0\n",
       "stocked kitchen                          1.0\n",
       "catered breakfast                        1.0\n",
       "evening                                  1.0\n",
       "discriminate                             1.0\n",
       "protected characteristics                1.0\n",
       ", deploy ,                               1.0\n",
       ", validate , interpret                   1.0\n",
       "engineering , statistics ,               1.0\n",
       "algebra , calculus , probability         1.0\n",
       "github , papers ,                        1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = None\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
